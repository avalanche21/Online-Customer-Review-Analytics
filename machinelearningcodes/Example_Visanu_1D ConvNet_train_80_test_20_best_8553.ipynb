{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pics/MLSb-T.png\" width=\"160\">\n",
    "<br><br>\n",
    "<center><u><H1>1D ConvNet on Sentiment Analysis</H1></u></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First run this from terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2527,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#start_time = time.time()\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2528,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2529,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Embedding, LSTM, CuDNNLSTM, Dropout, Flatten, Input\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2530,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(path='imdb.npz', num_words=None, skip_top=0,\n",
    "#               maxlen=None, seed=113,\n",
    "#               start_char=1, oov_char=2, index_from=3, **kwargs):\n",
    "\n",
    "#     with np.load(path) as f:\n",
    "#         x_train, labels_train = f['x_train'], f['y_train']\n",
    "#         x_test, labels_test = f['x_test'], f['y_test']\n",
    "\n",
    "#     np.random.seed(seed)\n",
    "#     indices = np.arange(len(x_train))\n",
    "#     np.random.shuffle(indices)\n",
    "#     x_train = x_train[indices]\n",
    "#     labels_train = labels_train[indices]\n",
    "\n",
    "#     indices = np.arange(len(x_test))\n",
    "#     np.random.shuffle(indices)\n",
    "#     x_test = x_test[indices]\n",
    "#     labels_test = labels_test[indices]\n",
    "\n",
    "#     xs = np.concatenate([x_train, x_test])\n",
    "#     labels = np.concatenate([labels_train, labels_test])\n",
    "\n",
    "#     if start_char is not None:\n",
    "#         xs = [[start_char] + [w + index_from for w in x] for x in xs]\n",
    "#     elif index_from:\n",
    "#         xs = [[w + index_from for w in x] for x in xs]\n",
    "\n",
    "#     if maxlen:\n",
    "#         xs, labels = _remove_long_seq(maxlen, xs, labels)\n",
    "#         if not xs:\n",
    "#             raise ValueError('After filtering for sequences shorter than maxlen=' +\n",
    "#                              str(maxlen) + ', no sequence was kept. '\n",
    "#                              'Increase maxlen.')\n",
    "#     if not num_words:\n",
    "#         num_words = max([max(x) for x in xs])\n",
    "\n",
    "#     if oov_char is not None:\n",
    "#         xs = [[w if (skip_top <= w < num_words) else oov_char for w in x]\n",
    "#               for x in xs]\n",
    "#     else:\n",
    "#         xs = [[w for w in x if skip_top <= w < num_words]\n",
    "#               for x in xs]\n",
    "\n",
    "#     idx = len(x_train)\n",
    "#     x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
    "#     x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n",
    "\n",
    "#     return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_data, train_labels), (test_data, test_labels) = load_data(path='imdb.npz',num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = load_data(path='imdb.npz',num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2534,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('consumer_complaints_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product', 'consumer_complaint_narrative'], dtype='object')"
      ]
     },
     "execution_count": 2535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = 'consumer_complaint_narrative', Y = 'product'\n",
    "\n",
    "df = df[['consumer_complaint_narrative','product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXXX has claimed I owe them {$27.00} for XXXX ...</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Due to inconsistencies in the amount owed that...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have an open and current mortgage with Chase...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        consumer_complaint_narrative          product\n",
       "0  XXXX has claimed I owe them {$27.00} for XXXX ...  Debt collection\n",
       "1  Due to inconsistencies in the amount owed that...    Consumer Loan\n",
       "2  In XX/XX/XXXX my wages that I earned at my job...         Mortgage\n",
       "3  I have an open and current mortgage with Chase...         Mortgage\n",
       "4  XXXX was submitted XX/XX/XXXX. At the time I s...         Mortgage"
      ]
     },
     "execution_count": 2537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66806"
      ]
     },
     "execution_count": 2538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66806 entries, 0 to 66805\n",
      "Data columns (total 2 columns):\n",
      "consumer_complaint_narrative    66806 non-null object\n",
      "product                         66806 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2540,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt collection            17552\n",
       "Mortgage                   14919\n",
       "Credit reporting           12526\n",
       "Credit card                 7929\n",
       "Bank account or service     5711\n",
       "Consumer Loan               3678\n",
       "Student loan                2128\n",
       "Prepaid card                 861\n",
       "Payday loan                  726\n",
       "Money transfers              666\n",
       "Other financial service      110\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 2540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "product",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "uid": "80c25816-9e38-11e9-9c1c-cf6d36e5b0e2",
         "x": [
          "Debt collection",
          "Mortgage",
          "Credit reporting",
          "Credit card",
          "Bank account or service",
          "Consumer Loan",
          "Student loan",
          "Prepaid card",
          "Payday loan",
          "Money transfers",
          "Other financial service"
         ],
         "y": [
          17552,
          14919,
          12526,
          7929,
          5711,
          3678,
          2128,
          861,
          726,
          666,
          110
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": "Number reviews in each rating",
        "titlefont": {
         "color": "#4D5663"
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": "",
         "titlefont": {
          "color": "#4D5663"
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": "Number of Reviews",
         "titlefont": {
          "color": "#4D5663"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div id=\"4ff27873-226f-4d64-aee6-87b07a7a1f2a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"4ff27873-226f-4d64-aee6-87b07a7a1f2a\", [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"product\", \"orientation\": \"v\", \"text\": \"\", \"x\": [\"Debt collection\", \"Mortgage\", \"Credit reporting\", \"Credit card\", \"Bank account or service\", \"Consumer Loan\", \"Student loan\", \"Prepaid card\", \"Payday loan\", \"Money transfers\", \"Other financial service\"], \"y\": [17552.0, 14919.0, 12526.0, 7929.0, 5711.0, 3678.0, 2128.0, 861.0, 726.0, 666.0, 110.0], \"type\": \"bar\", \"uid\": \"80c5c7b2-9e38-11e9-9c1c-cf6d36e5b0e2\"}], {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": \"Number reviews in each rating\", \"titlefont\": {\"color\": \"#4D5663\"}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": \"\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": \"Number of Reviews\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"4ff27873-226f-4d64-aee6-87b07a7a1f2a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"4ff27873-226f-4d64-aee6-87b07a7a1f2a\", [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"product\", \"orientation\": \"v\", \"text\": \"\", \"x\": [\"Debt collection\", \"Mortgage\", \"Credit reporting\", \"Credit card\", \"Bank account or service\", \"Consumer Loan\", \"Student loan\", \"Prepaid card\", \"Payday loan\", \"Money transfers\", \"Other financial service\"], \"y\": [17552.0, 14919.0, 12526.0, 7929.0, 5711.0, 3678.0, 2128.0, 861.0, 726.0, 666.0, 110.0], \"type\": \"bar\", \"uid\": \"80c5c7b2-9e38-11e9-9c1c-cf6d36e5b0e2\"}], {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": \"Number reviews in each rating\", \"titlefont\": {\"color\": \"#4D5663\"}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": \"\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": \"Number of Reviews\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['product'].value_counts().sort_values(ascending=False).iplot(kind='bar', yTitle='Number of Reviews', \n",
    "                                                                title='Number reviews in each rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-sampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using Ramdom Under Sampling (RUS) technique\n",
    "# X = df.iloc[:, :1].values\n",
    "# y = df.loc[:, 'Score'].values\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(return_indices=True)\n",
    "# X_rus, y_rus, id_rus = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rus[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_rus[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rus = X_rus[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2554,
   "metadata": {},
   "outputs": [],
   "source": [
    "##y_rus = y_rus[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'Text':X_rus,'Score':y_rus})\n",
    "\n",
    "## df = pd.DataFrame({'x':x, 'y':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot(index):\n",
    "    example = df[df.index == index][['consumer_complaint_narrative', 'product']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('product:', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am very disappointed that the CFPB did not help to resolve this fraudulant loan. # XXXX between XXXX XXXX and XXXX, FF ( AKA ) One West. Case # XXXX with CFPB. \n",
      "\n",
      "product: Mortgage\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I contacted Drivetime on several different occasions regarding a car loan I had with them account # XXXX i do not have the number for the other loan that was removed also from the credit bureau with a positive credit rating that was closed and paid in full. The company insisted on avoiding an agreement entered into by myself and XXXX of their company representative in a corporate position they have the agreed upon resolution and can provide your agency with a copy of the same because i do not have the capability to do so with my computer. Drivetime during the month of XXXX XXXX removed my credit reporting information from XXXX credit bureaus reporting agencies I believe XXXX and XXXX XXXX I discovered in or about XXXX XXXX that my positive credit ratings were no longer in the XXXX and XXXX credit bureaus and that another positive account for another car loan was no longer reporting in my credit file. these removals adversely affecxted my credit ratings and as such my ability to purchase something with a lower interest rate. I have never missed a payment to the Drivetime company on my car loans inclusive of XXXX XXXX XXXX XXXX different auto loans and for them to destroy my credit ratings is despicable. I spoke with XXXX today ( XXXX/XXXX/XXXX regarding those issues and his response to me was that Drivetime is now in the process of updating all consumers credit files and all of the consumers credit files were removed from the credit bureaus and is being updated however he does not know how the process is being performed who 's records are being updated/ corrected and what process or timeframes this process will take and furthermore does the process involves all consumers credit reports or are they updating reports for existing customers again which would not apply to me because my loans have been paid off and are closed however they did the same thing to my credit reports. Therefore the process would leave me with no credit ratings for accounts that I have paid off in good faith and never missed a payment in doing so however they kept trying to report my latest account as a repossession and or account was not satisfied I had them make the corrections and now back in XXXX or XXXX of XXXX I discovered yet again they tampered with my accounts by removing my positive information from the bureau for the account paid off in XXXX and for the account prior to that XXXX removed it from the credit bureau entirely and left the XXXX account in XXXX bureau I believe in the XXXX credit Bureau which was the same method of operations that has done to the existing consumers. Therefore Drivetime Representative XXXX gave me erroneous information about my accounts and for those reasons I am submitting a complaint to the Consumer Financial Protection Bureau based on the ruling implemented in terms of enforcement against the Drivetime XXXX XXXX for their violations of consumer rights dated XXXX XXXX, XXXX which is what they did to me in XXXX XXXX XXXX and prior to those dates in XXXX. \n",
      "\n",
      "product: Consumer Loan\n"
     ]
    }
   ],
   "source": [
    "print_plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2560,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df['consumer_complaint_narrative'] = df['consumer_complaint_narrative'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2561,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['consumer_complaint_narrative'] = df['consumer_complaint_narrative'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointed cfpb help resolve fraudulant loan # ff aka one west case # cfpb\n",
      "product: Mortgage\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contacted drivetime several different occasions regarding car loan account # number loan removed also credit bureau positive credit rating closed paid full company insisted avoiding agreement entered company representative corporate position agreed upon resolution provide agency copy capability computer drivetime month removed credit reporting information credit bureaus reporting agencies believe discovered positive credit ratings longer credit bureaus another positive account another car loan longer reporting credit file removals adversely affected credit ratings ability purchase something lower interest rate never missed payment drivetime company car loans inclusive different auto loans destroy credit ratings despicable spoke today regarding issues response drivetime process updating consumers credit files consumers credit files removed credit bureaus updated however know process performed records updated corrected process timeframes process take furthermore process involves consumers credit reports updating reports eisting customers would apply loans paid closed however thing credit reports therefore process would leave credit ratings accounts paid good faith never missed payment however kept trying report latest account repossession account satisfied make corrections back discovered yet tampered accounts removing positive information bureau account paid account prior removed credit bureau entirely left account bureau believe credit bureau method operations done eisting consumers therefore drivetime representative gave erroneous information accounts reasons submitting complaint consumer financial protection bureau based ruling implemented terms enforcement drivetime violations consumer rights dated prior dates\n",
      "product: Consumer Loan\n"
     ]
    }
   ],
   "source": [
    "print_plot(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test- only first 5000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2564,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66806"
      ]
     },
     "execution_count": 2564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2565,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claimed owe  years despite proof payment sent ...</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>due inconsistencies amount owed told bank amou...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wages earned job decreased almost half knew tr...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open current mortgage chase bank # chase repor...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submitted time submitted complaint dealt rushm...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        consumer_complaint_narrative          product\n",
       "0  claimed owe  years despite proof payment sent ...  Debt collection\n",
       "1  due inconsistencies amount owed told bank amou...    Consumer Loan\n",
       "2  wages earned job decreased almost half knew tr...         Mortgage\n",
       "3  open current mortgage chase bank # chase repor...         Mortgage\n",
       "4  submitted time submitted complaint dealt rushm...         Mortgage"
      ]
     },
     "execution_count": 2565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the dataframe index, inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2567,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claimed owe  years despite proof payment sent ...</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>due inconsistencies amount owed told bank amou...</td>\n",
       "      <td>Consumer Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wages earned job decreased almost half knew tr...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open current mortgage chase bank # chase repor...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submitted time submitted complaint dealt rushm...</td>\n",
       "      <td>Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        consumer_complaint_narrative          product\n",
       "0  claimed owe  years despite proof payment sent ...  Debt collection\n",
       "1  due inconsistencies amount owed told bank amou...    Consumer Loan\n",
       "2  wages earned job decreased almost half knew tr...         Mortgage\n",
       "3  open current mortgage chase bank # chase repor...         Mortgage\n",
       "4  submitted time submitted complaint dealt rushm...         Mortgage"
      ]
     },
     "execution_count": 2568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt collection            17552\n",
       "Mortgage                   14919\n",
       "Credit reporting           12526\n",
       "Credit card                 7929\n",
       "Bank account or service     5711\n",
       "Consumer Loan               3678\n",
       "Student loan                2128\n",
       "Prepaid card                 861\n",
       "Payday loan                  726\n",
       "Money transfers              666\n",
       "Other financial service      110\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 2569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56802 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['consumer_complaint_narrative'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (66806, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['consumer_complaint_narrative'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (66806, 11)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['product']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53444, 250) (53444, 11)\n",
      "(13362, 250) (13362, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finished data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start building CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53444 train_data\n",
      "13362 test_data\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), 'train_data')\n",
    "print(len(X_test), 'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2576,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256\n",
    "embedding_size = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences per time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     1    14     2   313    47    20    35    48  3114   313\n",
      "    47    10     2    13     1   221    45     5    35    48   868    48\n",
      "   649     2   601  1012    20    33    43  1428    33    65     5   574\n",
      "   313    47   590     5   320     5   110   100     6     5   274  1301\n",
      "  2612   282   624   561     1    10   153   313    47   601    10  1012\n",
      "    43   274     5    44   216   195   601    52     2   759    48  1012\n",
      "    20    16   820   227  3225   590   530  1013   256  1285     1   175\n",
      "   436   313    47 11780    10     2  1118    61  1325  6259     9  1819\n",
      "   590    52    43    44   514   191  3771     5   274   486   415  1516\n",
      "   101   901     1   956  1148   330   274     5   195   167  1289    16\n",
      "   118   304    61    48     2   118     5    35    10   326    48     5\n",
      "    35   704    13   431   100   274     5   225   441  1571   313    47\n",
      "     3   135   269    10   781   110  6055   441  1571   406  1148  1516\n",
      "   901     1   956  4713   896    12    16   236     1    35]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 2578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2579,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad  =  'post' #'pre'\n",
    "#Convert our lists to equal length sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=max_len, padding=pad, truncating=pad)\n",
    "X_test_pad = pad_sequences(X_test, maxlen=max_len, padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53444, 256)"
      ]
     },
     "execution_count": 2580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0, 2254,  123,  178,  222,    4,  182,  112,  181,   40,\n",
       "        193,  599,   39,  238,    4,  306,  515,   19, 5934,  137,   19,\n",
       "       3863,   37,   36,  682,  191,   46,  546,   20,    0,    0,    0,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 2581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,  325,  212,   25,   73, 1136,  323,\n",
       "       4894,  174,   11,   25, 4894,  174,  172,  603,  774,  158,  603,\n",
       "        714,   72,  273,    1,   10,  340,  364,   13,  158,  132,   39,\n",
       "       4894,  603,  325,  889,    1,   10,  190,  691, 1284,   72,    1,\n",
       "         10,  210,  588,   72,   42,  273,    1,   10,    0,    0,    0,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 2582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[4499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2583,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model (Model 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2584,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2585,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_len,\n",
    "                    name='layer_embedding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2586,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2587,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(MaxPooling1D(pool_size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2588,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2589,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(MaxPooling1D(pool_size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2590,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "# l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "# l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "# l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "# l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "# l_flat = Flatten()(l_pool3)\n",
    "# l_dense = Dense(128, activation='relu')(l_flat)\n",
    "# preds = Dense(2, activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model0.add(MaxPooling1D(pool_size=5))\n",
    "model0.add(MaxPooling1D(2))\n",
    "# model0.add(MaxPooling1D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2593,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2594,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2595,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.add(Dense(250, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model0.add(Dense(5, activation='softmax', name='classification'))\n",
    "\n",
    "model0.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2597,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 256, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 256, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 51, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 51, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 10, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 250)               160250    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 11)                2761      \n",
      "=================================================================\n",
      "Total params: 5,391,235\n",
      "Trainable params: 5,391,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45427 samples, validate on 8017 samples\n",
      "Epoch 1/4\n",
      "45427/45427 [==============================] - 55s 1ms/step - loss: 1.0374 - acc: 0.6513 - val_loss: 0.6758 - val_acc: 0.7886\n",
      "Epoch 2/4\n",
      "45427/45427 [==============================] - 42s 930us/step - loss: 0.5611 - acc: 0.8308 - val_loss: 0.5132 - val_acc: 0.8468\n",
      "Epoch 3/4\n",
      "45427/45427 [==============================] - 42s 933us/step - loss: 0.4334 - acc: 0.8714 - val_loss: 0.5046 - val_acc: 0.8458\n",
      "Epoch 4/4\n",
      "45427/45427 [==============================] - 42s 934us/step - loss: 0.3413 - acc: 0.8972 - val_loss: 0.4962 - val_acc: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde36e67780>"
      ]
     },
     "execution_count": 2599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "model0.fit(X_train_pad, Y_train, validation_split=0.15, epochs=4, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13362/13362 [==============================] - 4s 313us/step\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "eval_ = model0.evaluate(X_test_pad, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.52556\n",
      "Accuracy: 84.77%\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {0:.5}\".format(eval_[0]))\n",
    "print(\"Accuracy: {0:.2%}\".format(eval_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now show the F-1 score and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13362/13362 [==============================] - 4s 316us/step\n",
      "Test set\n",
      "  Loss: 0.526\n",
      "  Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "accr = model0.evaluate(X_test_pad,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(datum):\n",
    "    return np.argmax(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(Y_test.shape[0]):\n",
    "#     datum = Y_test[i]\n",
    "#     print('index: %d' % i)\n",
    "#     print('encoded datum: %s' % datum)\n",
    "#     decoded_datum = decode(Y_test[i])\n",
    "#     print('decoded datum: %s' % decoded_datum)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2606,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array([decode(i) for i in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2607,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model0.predict(X_test_pad, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model0.predict_classes(X_test_pad, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 2, ..., 4, 3, 3])"
      ]
     },
     "execution_count": 2608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847702\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2610,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6716274344081145"
      ]
     },
     "execution_count": 2610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, yhat_classes, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8477024397545277"
      ]
     },
     "execution_count": 2611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, yhat_classes, average='micro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2612,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80332168, 0.70596299, 0.80230978, 0.86055154, 0.86019444,\n",
       "       0.5751073 , 0.93855121, 0.        , 0.23931624, 0.76404494,\n",
       "       0.83854167])"
      ]
     },
     "execution_count": 2612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, yhat_classes, average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2613,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8434418391335528"
      ]
     },
     "execution_count": 2613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, yhat_classes, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10]\n",
      " [1155  746 1615 2502 3496  150 2941   21  153  168  415]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(Y_test, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2615,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1    2    3    4    5    6    8    9   10]\n",
      " [1133  713 1329 2611 3807   83 3064   81  188  353]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(yhat_classes, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 919   13   53   27   46    7   61    0    2   25    2]\n",
      " [   6  515   19   60   91    0   45    0    9    0    1]\n",
      " [ 100   30 1181  101  156    1   25    0    0   21    0]\n",
      " [   9   27   23 2200  214    0   23    0    1    0    5]\n",
      " [  18   44   40  148 3141    2   60    0   21    2   20]\n",
      " [  43    3    3    1   12   67   10    0    6    4    1]\n",
      " [   7   22    3   56   35    0 2818    0    0    0    0]\n",
      " [   2    1    2    1    7    3    2    0    1    0    2]\n",
      " [   7   48    0    1   63    0    6    0   28    0    0]\n",
      " [  20    0    5    1    5    1    0    0    0  136    0]\n",
      " [   2   10    0   15   37    2   14    0   13    0  322]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(Y_test, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_len,\n",
    "                    name='layer_embedding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(MaxPooling1D(pool_size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-604-32d0f9be83b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudnn_rnn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         self._cudnn_lstm = cudnn_rnn_ops.CudnnLSTM(\n\u001b[1;32m    422\u001b[0m             \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m# pylint: enable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# pylint: enable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudnn_rnn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlstm_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/rnn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_best_effort_input_batch_size\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbest_effort_input_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore_rnn_cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;31m# pylint: enable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/embedding_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxrange\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontrib_tensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_feature_cross_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/framework/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;31m# pylint: enable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_arg_scope\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontrib_add_arg_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_variable_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaver_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/gen_variable_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zero_initializer op does not support eager execution. Arg 'output_ref' is a ref.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ZeroInitializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   2544\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         _default_shape_function_registry.register(_call_cpp_shape_fn,\n\u001b[0;32m-> 2546\u001b[0;31m                                                   self._op_type)\n\u001b[0m\u001b[1;32m   2547\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         \u001b[0;31m# Ignore duplicate registrations of the weak value. This can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/registry.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, candidate, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# stack trace is [this_function, Register(), user_function,...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# so the user function is #2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0m_TYPE_TAG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_LOCATION_TAG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/traceback.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[0;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mclearcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/tokenize.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_buffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/tokenize.py\u001b[0m in \u001b[0;36mdetect_encoding\u001b[0;34m(readline)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_or_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBOM_UTF8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mbom_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/tokenize.py\u001b[0m in \u001b[0;36mread_or_stop\u001b[0;34m()\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_or_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1.add(CuDNNLSTM(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(1, activation='sigmoid', name='classification'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model1.fit(X_train_pad, y_train, validation_split=0.05, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_ = model1.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss: {0:.5}\".format(eval_[0]))\n",
    "print(\"Accuracy: {0:.2%}\".format(eval_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1D model with multiple kernel sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = []\n",
    "filter_sizes = [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_len,\n",
    "                    name='layer_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input = Input(shape=(max_len,), dtype='int32')\n",
    "embed_seq = embedding_layer(seq_input)\n",
    "\n",
    "for f in filter_sizes:\n",
    "    _conv = Conv1D(filters=128,kernel_size=f,activation='relu')(embed_seq)\n",
    "    _pool = MaxPooling1D(5)(_conv)\n",
    "    conv.append(_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_concat = concatenate(conv, axis=1)\n",
    "_conv1= Conv1D(128, 5, activation='relu')(_concat)\n",
    "_pool1 = MaxPooling1D(5)(_conv1)\n",
    "_pool1 = Dropout(0.5)(_pool1)\n",
    "_conv2 = Conv1D(128, 5, activation='relu')(_pool1)\n",
    "_pool2 = MaxPooling1D(5)(_conv2)\n",
    "_flat = Flatten()(_pool2)\n",
    "_flat = Dropout(0.5)(_flat)\n",
    "_dense = Dense(128, activation='relu')(_flat)\n",
    "preds = Dense(1, activation='sigmoid')(_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seq_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train_pad, y_train, validation_split=0.05, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_ = model.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss: {0:.5}\".format(eval_[0]))\n",
    "print(\"Accuracy: {0:.2%}\".format(eval_[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Total time used....\")\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "https://keras.io/layers/convolutional/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
